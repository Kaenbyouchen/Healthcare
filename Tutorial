每次在本地修改项目，然后更新github和discovery：
1) 本地电脑：提交并推送到 GitHub (或者直接用pycharm自带的commit and push)：
git status
git add .
git commit -m "本次修改的说明"
git push

2) Discovery：拉取更新、进入环境、运行：
# 登录
ssh zrui6736@discovery.usc.edu

# 进入项目（任选其一）
cd /project2/ruishanl_1185/zrui6736/Healthcare
# 或者（若建了快捷链接）
cd ~/Healthcare

激活conda环境(py310)：
source ~/.bashrc
conda activate /project2/ruishanl_1185/zrui6736/envs/py310

# 拉取最新代码 (一定要在/project2/ruishanl_1185/zrui6736/Healthcare里面)
git pull

# 轻量脚本可以直接跑（登录节点不要长时间/重负载）
python your_script.py

#分配GPU:进入bash：
# 申请 1 块 GPU，4 CPU 核，16GB 内存，1 小时
srun --partition=gpu \
     --gres=gpu:1 \
     --cpus-per-task=4 \
     --mem=16G \
     --time=01:00:00 \
     --pty bash
单行：srun --partition=gpu --gres=gpu:1 --cpus-per-task=4 --mem=16G --time=6:00:00 --pty bash

#查询所在目录：pwd
#查询所用环境：which python
#环境名：py310


复现代码：
1.nnUnet：
需要数据集格式：
$nnUNet_raw/Dataset001_xxx/
    imagesTr/
    labelsTr/
    imagesTs/
    dataset.json
命名规则要求：
影像：caseID_0000.nii.gz
标签：caseID.nii.gz
使用powershell：
cd "D:\Healthcare\nnunet\nnUNet_raw\Dataset001_Ruishan_T1_VIBE_Data_30"
看到确认提示符如PS D:\USC Research ...\Ruishan_T1_VIBE_Data_30>后
Get-ChildItem -File -Filter "*_img.nii.gz" | ForEach-Object { $new = $_.Name -replace "_img\.nii\.gz$", "_0000.nii.gz"; Rename-Item $_.FullName $new; Move-Item $new ".\imagesTr\" }
Get-ChildItem -File -Filter "*_lbl.nii.gz" | ForEach-Object { $new = $_.Name -replace "_lbl\.nii\.gz$", ".nii.gz"; Rename-Item $_.FullName $new; Move-Item $new ".\labelsTr\" }
以上是重命名加分配到特定文件夹

而后配置环境变量：设置原始数据、预处理数据和结果存放位置：
打开powershell管理员运行：
setx nnUNet_raw "D:\Healthcare\nnunet\nnUNet_raw"
setx nnUNet_preprocessed "D:\Healthcare\nnunet\nnUNet_preprocessed"
setx nnUNet_results "D:\Healthcare\nnunet\nnUNet_results"
验证：
echo $Env:nnUNet_raw
echo $Env:nnUNet_preprocessed
echo $Env:nnUNet_results

预处理：
使用anaconda propmt：(因为已设置好环境变量)
conda activate Healthcare
2D生成预处理：nnUNetv2_plan_and_preprocess -d 001 -c 2d --verify_dataset_integrity
3D生成预处理：nnUNetv2_plan_and_preprocess -d 041 -c 3d_fullres --verify_dataset_integrity
2D+3D：nnUNetv2_plan_and_preprocess -d 002 --verify_dataset_integrity
而后在nnUNet_preprocessed文件夹会生成一系列东西：

训练：
降低数据增强进程数：setx nnUNet_n_proc_DA 2
2D：nnUNetv2_train 001 2d 0 -device cpu



服务器上配置：
！！！每次要做的事：
source ~/.bashrc
conda activate /project2/ruishanl_1185/zrui6736/envs/py310
cd Healthcare
sbatch nnunet_train_2d.sbatch   :这里根据任务运行不同脚本，而后会得到例如Submitted batch job 2643808
另外脚本中已定义分配GPU数量时间等，以及训练并行线程，线程数，2D/3D等
tail -f nnunet_2d.2643808.out  中间这段号码就是上面给的，可持续跟踪训练
tail -f nnunet_2d.2643808.err  查看错误信息（没反应就进这里看看报没报错）
ctrl+c 退出，但是还可以一直训练
squeue -u $USER：查询是否有任务占用中
scancel 2643808:取消任务

# 安装 nnU-Net
pip install nnunetv2

设置环境变量：
nano ~/.bashrc
export nnUNet_raw=/project2/ruishanl_1185/zrui6736/nnunet/nnUNet_raw
export nnUNet_preprocessed=/project2/ruishanl_1185/zrui6736/nnunet/nnUNet_preprocessed
export nnUNet_results=/project2/ruishanl_1185/zrui6736/nnunet/nnUNet_results
Ctrl + O，回车保存，然后Ctrl + X退出
验证：source ~/.bashrc
echo $nnUNet_raw
echo $nnUNet_preprocessed
echo $nnUNet_results

激活conda环境(py310)：
source ~/.bashrc
conda activate /project2/ruishanl_1185/zrui6736/envs/py310

#分配GPU:申请 1 块 GPU，4 CPU 核，16GB 内存，6 小时
srun --partition=gpu --gres=gpu:1 --cpus-per-task=6 --mem=32G --time=6:00:00 --pty bash

激活后检查cuda：
python - <<'PY'
import torch; print("torch:", torch.__version__, "cuda?", torch.cuda.is_available())
PY

训练(共4种)：现在默认的是PlainConvUNet（2D / 3D fullres）
1. 2D(最好4CPU,24G内存)：把 3D 体数据切成单独 2D 切片训练；显存需求最低；速度快；对跨切片信息利用较少。
依次是nnU-Net 数据增强/数据加载的并行进程数为1,最多使用 4 个 CPU 线程，
export nnUNet_n_proc_DA=0; export OMP_NUM_THREADS=4; nnUNetv2_train 041 2d 0 -device cuda
如果是P100,显卡用这行（nnUNet_compile用不了）：
export nnUNet_compile=0 TORCHDYNAMO_DISABLE=1 TORCHINDUCTOR_DISABLE=1 nnUNet_n_proc_DA=0 OMP_NUM_THREADS=1; ulimit -n 4096; nnUNetv2_train 002 2d 0 -device cuda

2. 3D_fullres(最好6CPU,48G内存)：原始分辨率 3D patch 训练；最高精度但显存需求最大。
export nnUNet_compile=0; export nnUNet_n_proc_val=0 export; nnUNet_n_proc_DA=1; export OMP_NUM_THREADS=4; nnUNetv2_train 031 3d_fullres 0 -device cuda

3. 3d_lowres:先将体积下采样到较低分辨率，显存占用小；常与 cascade 联用。
nnUNetv2_train 002 3d_lowres 0 -device cuda

4. (已和解) 3d_cascade_fullres:级联策略：先训练 3d_lowres，再把预测的 coarse segmentation 作为先验去训练高分辨率模型；适合超大体积（脑、全腹部等）。
先运行：export nnUNet_raw=/project2/ruishanl_1185/zrui6736/Healthcare/nnunet/nnUNet_raw; export nnUNet_preprocessed=/project2/ruishanl_1185/zrui6736/Healthcare/nnunet/nnUNet_preprocessed; export nnUNet_results=/project2/ruishanl_1185/zrui6736/Healthcare/nnunet/nnUNet_results; OUT=$nnUNet_results/Dataset002_Abdomen/nnUNetTrainer__nnUNetPlans__3d_lowres/predicted_next_stage/3d_cascade_fullres; mkdir -p "$OUT"; nnUNetv2_predict -d 002 -c 3d_lowres -f 0 -tr nnUNetTrainer -i "$nnUNet_raw/Dataset002_Abdomen/imagesTr" -o "$OUT" --disable_tta -chk checkpoint_best.pth

nnUNetv2_train 002 3d_cascade_fullres 0 -device cuda

# ResEnc-M
nnUNetv2_train 041 3d_fullres 0 -tr nnUNetTrainer_ResEncM -device cuda

# ResEnc-L
nnUNetv2_train 002 3d_fullres 0 -tr nnUNetTrainer_ResEncL -device cuda

# ResEnc-XL
nnUNetv2_train 002 3d_fullres 0 -tr nnUNetTrainer_ResEncXL -device cuda


评测指标：
Dice：0–1 的重叠指标，值越高分割越准
各种loss：可以是负数，越负越好
Pseudo-Dice 是 nnU-Net 的主要评估指标，相当于每个类别的 Dice 系数
EMA pseudo Dice：nnU-Net 用指数移动平均 (EMA) 计算的整体 Dice（跨类别加权）


目前问题：爆worker
尝试：
# 4) 训练前先用“稳态”环境变量（先跑通，再提速）
export nnUNet_n_proc_DA=0        # 先关掉数据增强多进程（大概率罪魁祸首）
export OMP_NUM_THREADS=4         #这个也有可能
export MKL_NUM_THREADS=4         #这个也有可能
export OPENBLAS_NUM_THREADS=4
export MKL_THREADING_LAYER=GNU
export nnUNet_compile=0
export TORCHDYNAMO_DISABLE=1

连接失败在本地cmd运行：ssh zrui6736@discovery.usc.edu

source ~/.bashrc
conda activate /project2/ruishanl_1185/zrui6736/envs/py310
srun --partition=gpu --gres=gpu:1 --cpus-per-task=6 --mem=32G --time=24:00:00 --pty bash
module load screen
screen -S session_name   创建screen
screen -ls   查看screen
screen -D -r my_screen  进入screen
ctrl+A+D 离开screen
screen -X -S screen_name quit 永久关闭screen

记得安装hiddenlayer


3D worker崩，正在尝试：
# 1) 关闭 JIT 编译，加快启动
export nnUNet_compile=0

# 2) 关闭并行数据增强/验证（关键！把 worker 并发设为 0）
export nnUNet_n_proc_DA=0
export nnUNet_n_proc_val=0
# v2 有时用下面这组名字——两套都设更保险
export nnUNetv2_n_proc_DA=0
export nnUNetv2_n_proc_val=0

# 3) 避免 /dev/shm 问题（集群/容器常见）
export nnUNet_use_shm=False
export nnUNetv2_use_shm=False

# 4) 防止 OpenMP/BLAS 抢线程导致 worker 掉线
export OMP_NUM_THREADS=1
export MKL_NUM_THREADS=1
export OPENBLAS_NUM_THREADS=1

export nnUNet_compile=0; export nnUNet_n_proc_DA=0; export nnUNet_n_proc_val=0; export nnUNetv2_n_proc_DA=0; export nnUNetv2_n_proc_val=0; export nnUNet_use_shm=False; export nnUNetv2_use_shm=False; export OMP_NUM_THREADS=1; export MKL_NUM_THREADS=1; export OPENBLAS_NUM_THREADS=1

# 5) 开跑
nnUNetv2_train 002 3d_fullres 0 -device cuda

把M/L/XL模型复制到虚拟环境中：
cp /project2/ruishanl_1185/zrui6736/Healthcare/nnunet/nnunetv2/training/nnUNetTrainer/nnUNetTrainer_ResEncXL.py \
   /project2/ruishanl_1185/zrui6736/envs/py310/lib/python3.10/site-packages/nnunetv2/training/nnUNetTrainer/

设置训练结果储存位置：
export nnUNet_results=/project2/ruishanl_1185/zrui6736/nnunet_results/nnunet_L